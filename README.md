# *Emotion Recognition Using Speech Data*

*Description:*
Developed a machine learning model to recognize emotions from speech using the TESS (Toronto Emotional Speech Set) dataset. The project involved preprocessing audio data, extracting features, and building a deep learning model to classify emotions.

*Tools Used:*
- Python, Pandas, NumPy
- Seaborn, Matplotlib
- Librosa for audio processing
- Keras for model development

*Key Tasks:*
- Collected and preprocessed speech data from the TESS dataset.
- Visualized audio waveforms and spectrograms for exploratory analysis.
- Extracted MFCC (Mel-frequency cepstral coefficients) features from audio data.
- Built and trained an LSTM-based neural network for emotion classification.
- Evaluated model performance using metrics like accuracy and confusion matrix.

*Outcome:*
Successfully classified seven different emotions from speech with a significant accuracy, demonstrating the model's potential in applications such as sentiment analysis, virtual assistants, and mental health monitoring.

